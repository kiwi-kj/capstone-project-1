---
title: "Home Credit Default Risk"
subtitle: "Modelling"
author: "Kalyani Joshi"
output: 
  html_document:
    number_sections: yes
    toc: yes
    fig_width: 15
    fig_height: 10
    highlight: tango
    df_print: paged
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Set options ----
options(tibble.print_max = 40,
        tibble.print_min = 24,
        width = 222,
        pillar.min_title_chars = 15)

```

# Introduction  
Unbanked individuals represent both an underserved demographic as well as a typically untapped market by reputable creditors. Home Credit seeks to fill this gap in service. There are unique challenges that accompany establishing creditworthiness among a population that by definition has little to no financial history, verifiable assets, or traditional means to qualify for a loan.

## Project Scope
This project will utilize machine learning algorithms to develop a classification model which will use available data about Home Credit customers to improve prediction of those that are likely to repay loans granted by Home Credit. The team will test a number of possible classification models in order to develop the most accurate model on data outside the training data. A successful model will provide greater perfomance in terms of limiting Type II errors, than a simple prediction based upon majority class statistics and will allow Home Credit to loan to customers with confidence that repayment will in return grow available assets to the company in order to further its mission of providing credit to the underserved.

The dataset was previously explored and was determined to be suitable for data modelling purposes.  In this notebook we document the various modeling strategies explored as well as any included data preparation undertaken prior to modeling.  We then compare the various models performance and report our results.

# Data Preparation
## Load Libraries
```{r libraries}
library(ROSE)
library(tidyverse)
library(gmodels)
library(caret)
library(mlr)
library(xgboost)
library(parallel)
library(parallelMap)
library(ggplot2)
library(pROC)
```
## Standardized Data Set Preparation
In accordance with the information detailed in our previous EDA notebook, we created a standardized data set that utilized the same variables for all models.
```{r}
# Load data ----
app_train <- read_csv("application_train.csv")

bureau_df <- read_csv("bureau.csv")

desired_columns <- read_csv("desired_columns.csv")

# Identify numerically encoded categorical variables ----
num2fac <- app_train %>%
  select(where(is.numeric)) %>%
  mutate(across(everything(), as.character)) %>%
  select(where(~ all(!grepl("\\.|-", .)))) %>%
  #select(-c(own_car_age, hour_appr_process_start, matches("^(obs|def|amt|cnt)"))) %>%
  select(-c(OWN_CAR_AGE, HOUR_APPR_PROCESS_START, matches("^(OBS|DEF|AMY|CNT)"))) %>%
  colnames() 

# Create data frame ----
app_train1 <- app_train %>%
  # Select columns from 'desired_columns.csv'
  select(desired_columns$ColumnName) %>% 
  # Handling numerically encoded categorical variables
  mutate(across(c(where(is.character), all_of(num2fac)), factor), 
         # Fixing invalid NA's
         across(c(CODE_GENDER, ORGANIZATION_TYPE), 
                ~case_when(. != "XNA" ~ .)),
         # Replacing NA's in social circle columns with 0
         across(contains("SOCIAL_CIRCLE"), ~replace_na(., 0)),
         # Replacing NA's with 0
         across(c(AMT_REQ_CREDIT_BUREAU_HOUR, AMT_REQ_CREDIT_BUREAU_DAY,
                  AMT_REQ_CREDIT_BUREAU_WEEK, AMT_REQ_CREDIT_BUREAU_MON,
                  AMT_REQ_CREDIT_BUREAU_QRT, AMT_REQ_CREDIT_BUREAU_YEAR),
                ~replace_na(., factor("0"))),
         # Fixing unusual `DAYS_EMPLOYED` values
         DAYS_EMPLOYED = case_when(DAYS_EMPLOYED <= 0 ~ DAYS_EMPLOYED),
         # Creating ordinal version of `OWN_CAR_AGE`
         OWN_CAR_AGE2 = cut(OWN_CAR_AGE,
                            c(0, 5, 10, 15, Inf),
                            right = FALSE),
         OWN_CAR_AGE2 = case_when(FLAG_OWN_CAR == "N" ~ factor("No Car Owned"),
                                  .default = OWN_CAR_AGE2)) %>%
  # Creating aggregate variable from the `EXT_SOURCE_*` variables
  rowwise() %>%
  mutate(AVG_EXT_SCORE = mean(c_across(contains("EXT_"))),
         .after = EXT_SOURCE_3) %>%
  ungroup() %>%
  # Removing rows with NA's in below columns
  filter(if_all(c(FLAG_OWN_CAR, AMT_GOODS_PRICE, AMT_ANNUITY, 
                  CNT_FAM_MEMBERS, DAYS_LAST_PHONE_CHANGE),
                ~!is.na(.)))

# Aggregate bureau data ----
# __ Wide version data frame
bureau_agg_a <- bureau_df %>%
  # Seemed to be the most relevant credit types
  filter(CREDIT_TYPE %in% c("Consumer credit","Credit card","Car loan","Mortgage",
                            "Microloan","Loan for business development","Another type of loan"),
         # Ensure credit was actually given
         AMT_CREDIT_SUM > 0,
         # Thought this made most sense
         CREDIT_ACTIVE %in% c("Active", "Closed"),
         # It's unclear if they convert nominal currency values so kept only most common
         CREDIT_CURRENCY == "currency 1") %>%
  # Clean credit type values to use as column names
  mutate(CREDIT_TYPE = gsub(" +", "_", tolower(CREDIT_TYPE))) %>%
  group_by(SK_ID_CURR, CREDIT_TYPE) %>%
  summarise(avg_credit = mean(AMT_CREDIT_SUM),
            # Decided that average of ratios made more sense than ratio of averages
            avg_overage = mean(AMT_CREDIT_MAX_OVERDUE/AMT_CREDIT_SUM, na.rm = TRUE)) %>%
  pivot_wider(names_from = CREDIT_TYPE,
              values_from = c(avg_credit, avg_overage)) %>%
  ungroup()

# __ Version in EDA ----
bureau_agg_b <- bureau_df %>%
  group_by(SK_ID_CURR) %>%
  summarise(avg_days_credit = mean(DAYS_CREDIT, na.rm = TRUE),
            avg_credit_day_overdue = mean(CREDIT_DAY_OVERDUE, na.rm = TRUE),
            avg_days_credit_enddate = mean(DAYS_CREDIT_ENDDATE, na.rm = TRUE),
            avg_amt_credit_max_overdue = mean(AMT_CREDIT_MAX_OVERDUE, na.rm = TRUE),
            avg_cnt_credit_prolong = mean(CNT_CREDIT_PROLONG, na.rm = TRUE),
            avg_amt_credit_sum = mean(AMT_CREDIT_SUM, na.rm = TRUE),
            avg_amt_credit_sum_debt = mean(AMT_CREDIT_SUM_DEBT, na.rm = TRUE),
            avg_amt_credit_sum_limit = mean(AMT_CREDIT_SUM_LIMIT, na.rm = TRUE),
            avg_amt_credit_sum_overdue = mean(AMT_CREDIT_SUM_OVERDUE, na.rm = TRUE))

#Convert bureau_agg_b$SK_ID_CURR to factor
bureau_agg_b$SK_ID_CURR <- as.factor(bureau_agg_b$SK_ID_CURR)
#Join app_train1 and bureau_agg_b
app_train2 <- app_train1 %>% inner_join(bureau_agg_b)
# Cleanup
remove(app_train,bureau_agg_a,bureau_agg_b,bureau_df,desired_columns,num2fac)

```

## Data Pre-processing for Logistic Regression
```{r}
#Taking joined data to new variable
data_ktrain <-app_train2

#Function to calculate missing percentage
calculate_missing_percentage <- function(data) {
  missing_count <- colSums(is.na(data))
  missing_percentage <- missing_count / nrow(data) * 100
  result <- data.frame(Column = names(missing_count), Missing_Percentage = missing_percentage)
  result$Missing_Percentage <- sprintf("%.2f%%", result$Missing_Percentage)
  result <- result[result$Missing_Percentage != "0.00%", , drop = FALSE]
  result <- result[order(result$Missing_Percentage, decreasing = TRUE), , drop = FALSE]
  return(result)
}

#See missing percentage data
print(calculate_missing_percentage(data_ktrain))

# Handle missing values ----
# Drop columns with more than 49% missing data
missing_threshold <- 0.6
data_ktrain_clean <- data_ktrain %>%
    select(where(~ mean(!is.na(.)) > 1 - missing_threshold))

print(calculate_missing_percentage(data_ktrain_clean))

```

```{r}
#Data Imputation

# Numeric variables
data_ktrain_clean$avg_amt_credit_sum_limit <- ifelse(is.na(data_ktrain_clean$avg_amt_credit_sum_limit),
                                              mean(data_ktrain_clean$avg_amt_credit_sum_limit, na.rm = TRUE),
                                              data_ktrain_clean$avg_amt_credit_sum_limit)
data_ktrain_clean$EXT_SOURCE_3 <- ifelse(is.na(data_ktrain_clean$EXT_SOURCE_3),
                                   median(data_ktrain_clean$EXT_SOURCE_3, na.rm = TRUE),
                                   data_ktrain_clean$EXT_SOURCE_3)
data_ktrain_clean$avg_amt_credit_max_overdue <- ifelse(is.na(data_ktrain_clean$avg_amt_credit_max_overdue),
                                                 mean(data_ktrain_clean$avg_amt_credit_max_overdue, na.rm = TRUE),
                                                 data_ktrain_clean$avg_amt_credit_max_overdue)
data_ktrain_clean$avg_amt_credit_sum_debt <- ifelse(is.na(data_ktrain_clean$avg_amt_credit_sum_debt),
                                              mean(data_ktrain_clean$avg_amt_credit_sum_debt, na.rm = TRUE),
                                              data_ktrain_clean$avg_amt_credit_sum_debt)
data_ktrain_clean$DAYS_EMPLOYED <- ifelse(is.na(data_ktrain_clean$DAYS_EMPLOYED),
                                    median(data_ktrain_clean$DAYS_EMPLOYED, na.rm = TRUE),
                                    data_ktrain_clean$DAYS_EMPLOYED)
data_ktrain_clean$avg_days_credit_enddate <- ifelse(is.na(data_ktrain_clean$avg_days_credit_enddate),
                                              median(data_ktrain_clean$avg_days_credit_enddate, na.rm = TRUE),
                                              data_ktrain_clean$avg_days_credit_enddate)

# Categorical variables
data_ktrain_clean$OCCUPATION_TYPE <- ifelse(is.na(data_ktrain_clean$OCCUPATION_TYPE),
                                      levels(data_ktrain_clean$OCCUPATION_TYPE)[which.max(table(data_ktrain_clean$OCCUPATION_TYPE))],
                                      data_ktrain_clean$OCCUPATION_TYPE)
data_ktrain_clean$ORGANIZATION_TYPE <- ifelse(is.na(data_ktrain_clean$ORGANIZATION_TYPE),
                                        levels(data_ktrain_clean$ORGANIZATION_TYPE)[which.max(table(data_ktrain_clean$ORGANIZATION_TYPE))],
                                        data_ktrain_clean$ORGANIZATION_TYPE)
data_ktrain_clean$NAME_TYPE_SUITE <- ifelse(is.na(data_ktrain_clean$NAME_TYPE_SUITE),
                                      levels(data_ktrain_clean$NAME_TYPE_SUITE)[which.max(table(data_ktrain_clean$NAME_TYPE_SUITE))],
                                      data_ktrain_clean$NAME_TYPE_SUITE)
data_ktrain_clean$EXT_SOURCE_2 <- ifelse(is.na(data_ktrain_clean$EXT_SOURCE_2),
                                         median(data_ktrain_clean$EXT_SOURCE_2, na.rm = TRUE),
                                         data_ktrain_clean$EXT_SOURCE_2)

```

```{r}
#Upsampling the data

# Set seed for reproducibility
set.seed(123)

# Split data into training and testing sets
train_indices_glm <- sample(1:nrow(data_ktrain_clean), 0.7 * nrow(data_ktrain_clean))
train_glm <- data_ktrain_clean[train_indices_glm, ]
test_glm <- data_ktrain_clean[-train_indices_glm, ]

# Check the class distribution of the response variable
table(train_glm$TARGET)

# Upsample the minority class (positive class) in the training data using DMwR
train_glm_upsampled <- ovun.sample(TARGET ~ ., data = train_glm, method = "both", p = 0.5, seed = 123)$data

# Verify the class distribution of the upsampled training data
table(train_glm_upsampled$TARGET)

#Excluding SK_ID_CURR column
selected_features <- names(train_glm_upsampled)[2:86]
selected_features <- selected_features[sapply(train_glm_upsampled[selected_features], function(x) length(unique(x))) > 1]

```

Before upsampling, the class distribution is imbalanced, with Class 0 (the majority class) having significantly more observations than Class 1 (the minority class). This class imbalance can impact the performance of the logistic regression model, as it may be biased towards the majority class.

After applying upsampling, the class distribution becomes more balanced, with both classes having a similar number of observations. The upsampling technique increases the number of observations in the minority class (Class 1) to match the number of observations in the majority class (Class 0). This balanced dataset can help improve the model's ability to learn patterns and make accurate predictions for both classes.

```{r}
#Fitting model

model_glm <- glm(TARGET ~ ., data = train_glm_upsampled[(selected_features)], family = "binomial")

```

```{r}
# Get significant features
significant_features <- summary(model_glm)$coefficients[summary(model_glm)$coefficients[, "Pr(>|z|)"] < 0.05, ]
significant_features <- format(significant_features, scientific = FALSE)

# Get significant column names
significant_columns <- rownames(significant_features)

# Check if significant column names exist in upsampled file
existing_columns <- intersect(significant_columns, colnames(train_glm_upsampled))

# Get rows for significant columns
significant_rows <- train_glm_upsampled[, c("TARGET", existing_columns)]

# Save significant rows to a new file
write.csv(significant_rows, file = "significant_rows_upsampled.csv", row.names = FALSE)

str(significant_rows)
```

```{r}
# Read the significant_rows file
significant_rows <- read.csv("significant_rows_upsampled.csv")
```

```{r}
# Split the data into training and testing sets
set.seed(123)
train_indices_1 <- caret::createDataPartition(significant_rows$TARGET, p = 0.7, list = FALSE)
train_data_1 <- significant_rows[train_indices_1, ]
test_data_1 <- significant_rows[-train_indices_1, ]

```

```{r}
# Fit logistic regression model on training data for significant features
model <- glm(TARGET ~ ., data = train_data_1, family = "binomial")

```

# Model Performance
```{r}
# Predict probabilities for training and testing data
train_probs <- predict(model, train_data_1, type = "response")
test_pred <- predict(model, test_data_1, type = "response")

# Convert predicted values to factors with the same levels as the target variable
pred <- as.factor(ifelse(test_pred > 0.5, "1", "0"))

# Convert the actual target variable to a factor with the same levels
actual <- as.factor(test_data_1$TARGET)

# Calculate the confusion matrix
confusionMatrix(pred, actual)

```

```{r  results='hide'}
# Calculate AUC scores
train_auc_glm <- roc(train_data_1$TARGET, train_probs)$auc
test_auc_glm <- roc(test_data_1$TARGET, test_pred)$auc

# Display the AUC scores
output <- data.frame(
    Model = "Logistic Regression",
    "Training AUC" = train_auc_glm,
    "Testing AUC" = test_auc_glm
)
print(output)
```

```{r}
# Plt ROC Curve
# Calculate FPR, TPR, and thresholds
roc_data <- roc(test_data_1$TARGET, test_pred)
fpr <- roc_data$specificities
tpr <- roc_data$sensitivities
thresholds <- roc_data$thresholds

# Calculate AUC
auc <- auc(roc_data)

# Plot ROC curve
ggplot() +
    geom_line(data = data.frame(fpr = 1-fpr, tpr = tpr), aes(x = fpr, y = tpr), color = "darkorange") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "navy") +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
    labs(title = "ROC curve",
         x = "FPR",
         y = "TPR") +
    annotate(
        "text", x = 0.6, y = 0.2,
        label = paste0("AUC = ", round(auc, 3)),
        color = "darkorange"
    ) +
    theme_minimal() +
    theme(plot.title = element_text(size = 20),
          axis.title = element_text(size = 15))

```


```{r}
# Create display_importances function
display_importances <- function(feature_importance_df_) {
    feature_importance_df_ <- feature_importance_df_ %>%
        arrange(desc(importance))
    
    plt <- ggplot(feature_importance_df_, aes(x = importance, y = reorder(feature, importance, max))) +
        geom_bar(stat = "identity", fill = "steelblue") +
        labs(title = "Variable Importance",
             x = "Importance",
             y = "Feature") +
        theme_minimal()
    
    print(plt)
}

# Get the important feature names
important_features <- colnames(significant_rows)[-1]

# Calculate the importance values based on the number of features
importance_values <- 1:length(important_features)

# Create the feature_importance_df data frame
feature_importance_df <- data.frame(
    feature = important_features,
    importance = importance_values
)

# Call the display_importance function to get variable importance plot
display_importances(feature_importance_df)
```

Based on the analysis of the logistic regression model, the variables avg_amt_credit_sum_debt have the most significant impact on the outcome values. These variables, along with the credit_sum and max_overdue, play an important role in predicting the outcomes.

In addition to the external data sources, other important variables for predicting outcomes include the days_employed and days_birth.